{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Tuple, Dict\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NERDataset:\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"Initialize NER dataset from TSV file\"\"\"\n",
    "        self.sentences: List[List[str]] = []\n",
    "        self.labels: List[List[str]] = []\n",
    "        self._load_data(file_path)\n",
    "        \n",
    "    def _load_data(self, file_path: str) -> None:\n",
    "        \"\"\"Load and parse TSV data with progress bar\"\"\"\n",
    "        current_sentence = []\n",
    "        current_labels = []\n",
    "        \n",
    "        # First pass to count lines\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            total_lines = sum(1 for _ in f)\n",
    "        \n",
    "        # Second pass to load data\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            pbar = tqdm(f, total=total_lines, desc=f\"Loading {file_path}\")\n",
    "            for line in pbar:\n",
    "                line = line.strip()\n",
    "                if line == '':\n",
    "                    if current_sentence:\n",
    "                        self.sentences.append(current_sentence)\n",
    "                        self.labels.append(current_labels)\n",
    "                        current_sentence = []\n",
    "                        current_labels = []\n",
    "                else:\n",
    "                    parts = line.split('\\t')\n",
    "                    if len(parts) >= 2:\n",
    "                        word = parts[0].lower()\n",
    "                        label = parts[1]\n",
    "                        current_sentence.append(word)\n",
    "                        current_labels.append(label)\n",
    "            \n",
    "            if current_sentence:\n",
    "                self.sentences.append(current_sentence)\n",
    "                self.labels.append(current_labels)\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.sentences)} sentences from {file_path}\")\n",
    "\n",
    "class Word2VecNERModel(nn.Module):\n",
    "    def __init__(self, embedding_dim: int, hidden_dim: int, vocab_size: int, num_classes: int, dropout: float = 0.5):\n",
    "        \"\"\"Initialize the NER model architecture\"\"\"\n",
    "        super(Word2VecNERModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, \n",
    "                           bidirectional=True, num_layers=2, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "class NERProcessor:\n",
    "    def __init__(self, embedding_dim: int = 100, hidden_dim: int = 128, batch_size: int = 32):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.word2idx: Dict[str, int] = {}\n",
    "        self.label2idx: Dict[str, int] = {}\n",
    "        self.idx2word: Dict[int, str] = {}\n",
    "        self.idx2label: Dict[int, str] = {}\n",
    "        \n",
    "    def prepare_data(self, train_dataset: NERDataset, test_dataset: NERDataset) -> Tuple[int, int]:\n",
    "        \"\"\"Prepare vocabularies and Word2Vec model with progress tracking\"\"\"\n",
    "        logger.info(\"Starting data preparation...\")\n",
    "        \n",
    "        # Build vocabularies\n",
    "        words = set()\n",
    "        labels = set()\n",
    "        \n",
    "        # Process both datasets with progress tracking\n",
    "        for dataset_name, dataset in [(\"training\", train_dataset), (\"test\", test_dataset)]:\n",
    "            pbar = tqdm(zip(dataset.sentences, dataset.labels), \n",
    "                       total=len(dataset.sentences),\n",
    "                       desc=f\"Processing {dataset_name} dataset\")\n",
    "            for sentence, sentence_labels in pbar:\n",
    "                words.update(sentence)\n",
    "                labels.update(sentence_labels)\n",
    "        \n",
    "        # Create mappings\n",
    "        logger.info(\"Creating vocabulary mappings...\")\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(words)}\n",
    "        self.label2idx = {label: idx for idx, label in enumerate(labels)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.idx2label = {idx: label for label, idx in self.label2idx.items()}\n",
    "        \n",
    "        # Train Word2Vec model\n",
    "        logger.info(\"Training Word2Vec model...\")\n",
    "        combined_sentences = train_dataset.sentences + test_dataset.sentences\n",
    "        self.word2vec = Word2Vec(sentences=tqdm(combined_sentences, desc=\"Training Word2Vec\"),\n",
    "                                vector_size=self.embedding_dim,\n",
    "                                window=5,\n",
    "                                min_count=1,\n",
    "                                workers=4)\n",
    "        \n",
    "        logger.info(f\"Completed data preparation:\")\n",
    "        logger.info(f\"- Vocabulary size: {len(words)}\")\n",
    "        logger.info(f\"- Number of labels: {len(labels)}\")\n",
    "        return len(words), len(labels)\n",
    "\n",
    "    def create_model(self, vocab_size: int, num_classes: int) -> Word2VecNERModel:\n",
    "        \"\"\"Create and initialize the NER model with Word2Vec embeddings\"\"\"\n",
    "        logger.info(\"Initializing model...\")\n",
    "        model = Word2VecNERModel(self.embedding_dim, self.hidden_dim, vocab_size, num_classes)\n",
    "        \n",
    "        # Initialize embedding layer with progress tracking\n",
    "        embedding_weights = np.zeros((vocab_size, self.embedding_dim))\n",
    "        pbar = tqdm(self.word2idx.items(), total=len(self.word2idx), desc=\"Initializing embeddings\")\n",
    "        for word, idx in pbar:\n",
    "            if word in self.word2vec.wv:\n",
    "                embedding_weights[idx] = self.word2vec.wv[word]\n",
    "        \n",
    "        model.embedding.weight.data.copy_(torch.from_numpy(embedding_weights))\n",
    "        logger.info(\"Model initialization completed\")\n",
    "        return model\n",
    "\n",
    "    def prepare_sequence(self, seq: List[str]) -> torch.Tensor:\n",
    "        \"\"\"Convert word sequence to tensor of indices\"\"\"\n",
    "        idxs = [self.word2idx[w] for w in seq]\n",
    "        return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "    def prepare_labels(self, labels: List[str]) -> torch.Tensor:\n",
    "        \"\"\"Convert label sequence to tensor of indices\"\"\"\n",
    "        idxs = [self.label2idx[l] for l in labels]\n",
    "        return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def train_model(model: Word2VecNERModel, \n",
    "                train_dataset: NERDataset, \n",
    "                processor: NERProcessor, \n",
    "                num_epochs: int = 10, \n",
    "                learning_rate: float = 0.001) -> List[float]:\n",
    "    \"\"\"Train the NER model with detailed progress tracking\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    training_losses = []\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Training on device: {device}\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        pbar = tqdm(zip(train_dataset.sentences, train_dataset.labels),\n",
    "                   total=len(train_dataset.sentences),\n",
    "                   desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for sentence, labels in pbar:\n",
    "            model.zero_grad()\n",
    "            \n",
    "            sentence_in = processor.prepare_sequence(sentence).unsqueeze(0).to(device)\n",
    "            targets = processor.prepare_labels(labels).to(device)\n",
    "            \n",
    "            outputs = model(sentence_in)\n",
    "            loss = criterion(outputs.squeeze(0), targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataset.sentences)\n",
    "        training_losses.append(avg_loss)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        logger.info(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        logger.info(f\"- Average loss: {avg_loss:.4f}\")\n",
    "        logger.info(f\"- Time taken: {epoch_time:.2f}s\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    logger.info(f\"Training completed in {total_time:.2f}s\")\n",
    "    return training_losses\n",
    "\n",
    "def evaluate_model(model: Word2VecNERModel, \n",
    "                  test_dataset: NERDataset, \n",
    "                  processor: NERProcessor) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate the model with comprehensive performance metrics\"\"\"\n",
    "    logger.info(\"Starting comprehensive model evaluation...\")\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(zip(test_dataset.sentences, test_dataset.labels),\n",
    "                   total=len(test_dataset.sentences),\n",
    "                   desc=\"Evaluating\")\n",
    "        \n",
    "        for sentence, labels in pbar:\n",
    "            sentence_in = processor.prepare_sequence(sentence).unsqueeze(0).to(device)\n",
    "            outputs = model(sentence_in)\n",
    "            _, predicted = torch.max(outputs.squeeze(0), 1)\n",
    "            \n",
    "            true_labels.extend([processor.label2idx[l] for l in labels])\n",
    "            predicted_labels.extend(predicted.cpu().tolist())\n",
    "    \n",
    "    # Convert indices back to labels\n",
    "    true_labels = [processor.idx2label[l] for l in true_labels]\n",
    "    predicted_labels = [processor.idx2label[l] for l in predicted_labels]\n",
    "    \n",
    "    # Calculate comprehensive metrics\n",
    "    report = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "    \n",
    "    # Print detailed performance analysis\n",
    "    logger.info(\"\\n\" + \"=\"*50)\n",
    "    logger.info(\"DETAILED PERFORMANCE ANALYSIS\")\n",
    "    logger.info(\"=\"*50)\n",
    "    \n",
    "    # Overall Metrics\n",
    "    logger.info(\"\\nOVERALL METRICS:\")\n",
    "    logger.info(f\"Macro Avg Precision: {report['macro avg']['precision']:.4f}\")\n",
    "    logger.info(f\"Macro Avg Recall: {report['macro avg']['recall']:.4f}\")\n",
    "    logger.info(f\"Macro Avg F1-Score: {report['macro avg']['f1-score']:.4f}\")\n",
    "    logger.info(f\"Weighted Avg F1-Score: {report['weighted avg']['f1-score']:.4f}\")\n",
    "    \n",
    "    # Per-Class Performance\n",
    "    logger.info(\"\\nPER-CLASS PERFORMANCE:\")\n",
    "    logger.info(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
    "    logger.info(\"-\" * 65)\n",
    "    \n",
    "    # Sort classes by F1-score for better analysis\n",
    "    class_metrics = {\n",
    "        label: metrics for label, metrics in report.items() \n",
    "        if label not in ['accuracy', 'macro avg', 'weighted avg']\n",
    "    }\n",
    "    sorted_classes = sorted(class_metrics.items(), \n",
    "                          key=lambda x: x[1]['f1-score'], \n",
    "                          reverse=True)\n",
    "    \n",
    "    for label, metrics in sorted_classes:\n",
    "        logger.info(f\"{label:<15} {metrics['precision']:<12.4f} \"\n",
    "                   f\"{metrics['recall']:<12.4f} {metrics['f1-score']:<12.4f} \"\n",
    "                   f\"{metrics['support']:<10}\")\n",
    "    \n",
    "    # Performance Distribution Analysis\n",
    "    f1_scores = [metrics['f1-score'] for metrics in class_metrics.values()]\n",
    "    logger.info(\"\\nF1-SCORE DISTRIBUTION:\")\n",
    "    logger.info(f\"Maximum F1-Score: {max(f1_scores):.4f}\")\n",
    "    logger.info(f\"Minimum F1-Score: {min(f1_scores):.4f}\")\n",
    "    logger.info(f\"F1-Score Range: {max(f1_scores) - min(f1_scores):.4f}\")\n",
    "    logger.info(f\"Standard Deviation: {np.std(f1_scores):.4f}\")\n",
    "    \n",
    "    # Confusion Matrix Analysis\n",
    "    logger.info(\"\\nCONFUSION MATRIX STATISTICS:\")\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    logger.info(f\"Number of True Positives: {np.sum(np.diag(conf_matrix))}\")\n",
    "    logger.info(f\"Total Predictions: {np.sum(conf_matrix)}\")\n",
    "    logger.info(f\"Overall Accuracy: {report['accuracy']:.4f}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Starting NER system training and evaluation\")\n",
    "    \n",
    "    # Load datasets\n",
    "    train_dataset = NERDataset('train.tsv')\n",
    "    test_dataset = NERDataset('test_gold.tsv')\n",
    "    \n",
    "    # Initialize processor and prepare data\n",
    "    processor = NERProcessor(embedding_dim=100, hidden_dim=128, batch_size=32)\n",
    "    vocab_size, num_classes = processor.prepare_data(train_dataset, test_dataset)\n",
    "    \n",
    "    # Create and train model\n",
    "    model = processor.create_model(vocab_size, num_classes)\n",
    "    training_losses = train_model(model, train_dataset, processor, num_epochs=10)\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics = evaluate_model(model, test_dataset, processor)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    logger.info(f\"Total execution time: {total_time:.2f}s\")\n",
    "    \n",
    "    # Get evaluation results\n",
    "    metrics = evaluate_model(model, test_dataset, processor)\n",
    "\n",
    "    # Get the actual class labels from the dataset\n",
    "    class_labels = list(metrics.keys())  # Get all keys from the metrics dictionary\n",
    "    class_labels = [label for label in class_labels if label not in ['accuracy', 'macro avg', 'weighted avg']] # Filter out non-class labels\n",
    "\n",
    "    # Access specific metrics for the first class label (or any other label you choose)\n",
    "    # You can modify this to loop through and access metrics for all class labels\n",
    "    class_name = class_labels[0]  # Choose the first class label\n",
    "    class_metrics = {\n",
    "        'precision': metrics[class_name]['precision'],\n",
    "        'recall': metrics[class_name]['recall'],\n",
    "        'f1': metrics[class_name]['f1-score']\n",
    "    }\n",
    "    # Overall performance\n",
    "    overall_metrics = {\n",
    "        'macro_precision': metrics['macro avg']['precision'],\n",
    "        'macro_recall': metrics['macro avg']['recall'],\n",
    "        'macro_f1': metrics['macro avg']['f1-score']\n",
    "    }\n",
    "    return model, metrics, training_losses\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
