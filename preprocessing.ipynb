{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the IOB file for NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOB file created at C:\\S24-25\\TxM\\IOB\\cadec_iob.tsv\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "annotation_dir = r\"C:\\S24-25\\TxM\\CADEC.v2\\cadec\\original\"\n",
    "text_dir = r\"C:\\S24-25\\TxM\\CADEC.v2\\cadec\\text\"\n",
    "output_file_path = r\"C:\\S24-25\\TxM\\IOB\\cadec_iob.tsv\"\n",
    "\n",
    "# Tag mappings\n",
    "tag_mapping = {\n",
    "    \"ADR\": \"ADR\",\n",
    "    \"Drug\": \"DRU\",\n",
    "    \"Disease\": \"DIS\",\n",
    "    \"Symptom\": \"SYM\"\n",
    "}\n",
    "\n",
    "def parse_annotations(annotation_file):\n",
    "    annotations = []\n",
    "    with open(annotation_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"T\"):\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                tag_info = parts[1].replace(\";\", \" \").split()  # Replace ; with space\n",
    "                tag = tag_info[0]\n",
    "                start = int(tag_info[1])\n",
    "                end = int(tag_info[2])\n",
    "                text = parts[2]\n",
    "                if tag in tag_mapping:\n",
    "                    annotations.append((start, end, tag_mapping[tag], text))\n",
    "    return annotations\n",
    "\n",
    "def generate_iob(text, annotations):\n",
    "    tokens = text.split()\n",
    "    positions = []\n",
    "    iob_tags = [\"O\"] * len(tokens)\n",
    "\n",
    "    current_position = 0\n",
    "    for idx, token in enumerate(tokens):\n",
    "        positions.append((current_position, current_position + len(token)))\n",
    "        current_position += len(token) + 1  # Account for space\n",
    "\n",
    "    for start, end, iob_tag, _ in annotations:\n",
    "        for idx, (token_start, token_end) in enumerate(positions):\n",
    "            if token_start >= start and token_end <= end:\n",
    "                if token_start == start:\n",
    "                    iob_tags[idx] = f\"B-{iob_tag}\"\n",
    "                else:\n",
    "                    iob_tags[idx] = f\"I-{iob_tag}\"\n",
    "\n",
    "    return zip(tokens, iob_tags)\n",
    "\n",
    "def process_files(annotation_dir, text_dir, output_file):\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as output:\n",
    "        for annotation_file in os.listdir(annotation_dir):\n",
    "            if annotation_file.endswith(\".ann\"):\n",
    "                base_name = os.path.splitext(annotation_file)[0]\n",
    "                annotation_path = os.path.join(annotation_dir, annotation_file)\n",
    "                text_path = os.path.join(text_dir, base_name + \".txt\")\n",
    "\n",
    "                if os.path.exists(text_path):\n",
    "                    with open(text_path, \"r\", encoding=\"utf-8\") as text_file:\n",
    "                        text = text_file.read()\n",
    "\n",
    "                    annotations = parse_annotations(annotation_path)\n",
    "                    iob_data = generate_iob(text, annotations)\n",
    "\n",
    "                    for token, tag in iob_data:\n",
    "                        output.write(f\"{token}\\t{tag}\\n\")\n",
    "\n",
    "                    output.write(\"\\n\")  # Separate files with a blank line\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Process all files\n",
    "process_files(annotation_dir, text_dir, output_file_path)\n",
    "\n",
    "print(f\"IOB file created at {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits saved in C:\\S24-25\\TxM\\dataset\n",
      "Train examples: 998\n",
      "Validation examples: 124\n",
      "Test examples: 126\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "def read_iob_file(file_path):\n",
    "    \"\"\"Read IOB file and split into paragraphs\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read().strip()\n",
    "    # Split into paragraphs (sections separated by blank lines)\n",
    "    paragraphs = [p.strip() for p in content.split('\\n\\n') if p.strip()]\n",
    "    return paragraphs\n",
    "\n",
    "def save_tsv(file_path, data):\n",
    "    \"\"\"Save data to a TSV file\"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        for paragraph in data:\n",
    "            for line in paragraph.split('\\n'):\n",
    "                if line.strip():\n",
    "                    writer.writerow(line.split('\\t'))\n",
    "            writer.writerow([])  # Blank line to separate paragraphs\n",
    "\n",
    "def create_o_tag_version(data):\n",
    "    \"\"\"Create a version of the dataset with all tags replaced by 'O'\"\"\"\n",
    "    o_tag_data = []\n",
    "    for paragraph in data:\n",
    "        lines = []\n",
    "        for line in paragraph.split('\\n'):\n",
    "            if line.strip():\n",
    "                token, _ = line.split('\\t')  # Split token and tag\n",
    "                lines.append(f\"{token}\\tO\")\n",
    "        o_tag_data.append('\\n'.join(lines))\n",
    "    return o_tag_data\n",
    "\n",
    "def main():\n",
    "    input_file = r'C:\\S24-25\\TxM\\IOB\\cadec_iob.tsv'  # Input file\n",
    "    output_dir = r'C:\\S24-25\\TxM\\dataset'  # Output directory\n",
    "\n",
    "    # Read and split data\n",
    "    paragraphs = read_iob_file(input_file)\n",
    "    if not paragraphs:\n",
    "        print(\"No paragraphs found in input file. Please check the file format.\")\n",
    "        return\n",
    "\n",
    "    random.shuffle(paragraphs)  # Shuffle paragraphs\n",
    "\n",
    "    # Calculate split sizes\n",
    "    total_size = len(paragraphs)\n",
    "    train_size = int(total_size * 0.8)\n",
    "    val_size = int(total_size * 0.1)\n",
    "\n",
    "    # Create splits\n",
    "    train_data = paragraphs[:train_size]\n",
    "    val_data = paragraphs[train_size:train_size + val_size]\n",
    "    test_data = paragraphs[train_size + val_size:]\n",
    "\n",
    "    # Create O-tag versions\n",
    "    val_o_tag_data = create_o_tag_version(val_data)\n",
    "    test_o_tag_data = create_o_tag_version(test_data)\n",
    "\n",
    "    # Save splits as TSV files\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    save_tsv(os.path.join(output_dir, 'train.tsv'), train_data)\n",
    "    save_tsv(os.path.join(output_dir, 'val_gold.tsv'), val_data)\n",
    "    save_tsv(os.path.join(output_dir, 'val.tsv'), val_o_tag_data)\n",
    "    save_tsv(os.path.join(output_dir, 'test_gold.tsv'), test_data)\n",
    "    save_tsv(os.path.join(output_dir, 'test.tsv'), test_o_tag_data)\n",
    "\n",
    "    print(f\"Splits saved in {output_dir}\")\n",
    "    print(f\"Train examples: {len(train_data)}\")\n",
    "    print(f\"Validation examples: {len(val_data)}\")\n",
    "    print(f\"Test examples: {len(test_data)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(42)  # For reproducibility\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TxM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
