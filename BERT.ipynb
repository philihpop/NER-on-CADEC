{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available. Check your setup.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "# Function to read IOB files and split into paragraphs\n",
    "def read_iob_file(file_path):\n",
    "    \"\"\"Read IOB file and convert to token-label samples\"\"\"\n",
    "    examples = []\n",
    "    words, labels = [], []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                token, label = line.split(\"\\t\")\n",
    "                words.append(token)\n",
    "                labels.append(label.strip())\n",
    "            else:\n",
    "                # End of a sample\n",
    "                if words and labels:\n",
    "                    examples.append({\"tokens\": words, \"labels\": labels})\n",
    "                    words, labels = [], []\n",
    "    # Add the last example if file doesn't end with a blank line\n",
    "    if words and labels:\n",
    "        examples.append({\"tokens\": words, \"labels\": labels})\n",
    "    return examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 998, Val samples: 124, Test samples: 126\n"
     ]
    }
   ],
   "source": [
    "# Load datasets using the updated function\n",
    "train_path = 'C:\\\\S24-25\\\\TxM\\\\dataset\\\\train.tsv'\n",
    "val_path = 'C:\\\\S24-25\\\\TxM\\\\dataset\\\\val_gold.tsv'\n",
    "test_path = 'C:\\\\S24-25\\\\TxM\\\\dataset\\\\test_gold.tsv'\n",
    "train_data = read_iob_file(train_path)\n",
    "val_data = read_iob_file(val_path)\n",
    "test_data = read_iob_file(test_path)\n",
    "\n",
    "print(f\"Train samples: {len(train_data)}, Val samples: {len(val_data)}, Test samples: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and Align Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 998/998 [00:00<00:00, 2618.51 examples/s]\n",
      "Map: 100%|██████████| 126/126 [00:00<00:00, 2290.75 examples/s]\n",
      "Map: 100%|██████████| 124/124 [00:00<00:00, 2724.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "# Define label mappings\n",
    "label_list = [\"O\", \"B-ADR\", \"I-ADR\", \"B-DRU\", \"I-DRU\", \"B-DIS\", \"I-DIS\", \"B-SYM\", \"I-SYM\"]\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True, padding=True\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        aligned_labels = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned_labels.append(-100)  # Ignore padding\n",
    "            elif word_idx != previous_word_idx:\n",
    "                aligned_labels.append(label_to_id[label[word_idx]])\n",
    "            else:\n",
    "                aligned_labels.append(label_to_id[label[word_idx]])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(aligned_labels)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = Dataset.from_list(train_data).map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = Dataset.from_list(test_data).map(tokenize_and_align_labels, batched=True)\n",
    "val_dataset = Dataset.from_list(val_data).map(tokenize_and_align_labels, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train and evaluate with default parameters on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/189 [00:04<01:09,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4865, 'grad_norm': 1.8258541822433472, 'learning_rate': 1.8941798941798943e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 20/189 [00:08<01:03,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5903, 'grad_norm': 1.1083478927612305, 'learning_rate': 1.7883597883597884e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 30/189 [00:12<00:59,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4873, 'grad_norm': 1.5807186365127563, 'learning_rate': 1.6825396825396828e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 40/189 [00:16<00:55,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.366, 'grad_norm': 0.6019790172576904, 'learning_rate': 1.576719576719577e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 50/189 [00:19<00:53,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3875, 'grad_norm': 1.2651851177215576, 'learning_rate': 1.470899470899471e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 60/189 [00:23<00:50,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.336, 'grad_norm': 0.7563637495040894, 'learning_rate': 1.3650793650793652e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 63/189 [00:24<00:39,  3.16it/s]c:\\Users\\HikaLipp\\miniconda3\\envs\\TxM\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                \n",
      " 33%|███▎      | 63/189 [00:25<00:39,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3093837797641754, 'eval_ADR': {'precision': 0.33065595716198126, 'recall': 0.37142857142857144, 'f1': 0.34985835694050993, 'number': 665}, 'eval_DIS': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 58}, 'eval_DRU': {'precision': 0.7016317016317016, 'recall': 0.7525, 'f1': 0.7261761158021713, 'number': 400}, 'eval_SYM': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 50}, 'eval_overall_precision': 0.46598639455782315, 'eval_overall_recall': 0.46717817561807334, 'eval_overall_f1': 0.46658152405278847, 'eval_overall_accuracy': 0.8985115911485775, 'eval_runtime': 1.1432, 'eval_samples_per_second': 110.215, 'eval_steps_per_second': 6.998, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 70/189 [00:29<00:53,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2654, 'grad_norm': 0.7308688163757324, 'learning_rate': 1.2592592592592593e-05, 'epoch': 1.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 80/189 [00:33<00:40,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2766, 'grad_norm': 1.024377703666687, 'learning_rate': 1.1534391534391536e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 90/189 [00:37<00:37,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2889, 'grad_norm': 1.607595443725586, 'learning_rate': 1.0476190476190477e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 100/189 [00:40<00:33,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2724, 'grad_norm': 0.8333780765533447, 'learning_rate': 9.417989417989418e-06, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 110/189 [00:44<00:29,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2648, 'grad_norm': 0.8623822331428528, 'learning_rate': 8.35978835978836e-06, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 120/189 [00:48<00:25,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2457, 'grad_norm': 1.1264517307281494, 'learning_rate': 7.301587301587301e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 126/189 [00:50<00:19,  3.27it/s]c:\\Users\\HikaLipp\\miniconda3\\envs\\TxM\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                 \n",
      " 67%|██████▋   | 126/189 [00:51<00:19,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26164135336875916, 'eval_ADR': {'precision': 0.38826185101580135, 'recall': 0.5172932330827068, 'f1': 0.443584784010316, 'number': 665}, 'eval_DIS': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 58}, 'eval_DRU': {'precision': 0.7941834451901566, 'recall': 0.8875, 'f1': 0.8382526564344746, 'number': 400}, 'eval_SYM': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 50}, 'eval_overall_precision': 0.5243810952738185, 'eval_overall_recall': 0.5959079283887468, 'eval_overall_f1': 0.5578611332801278, 'eval_overall_accuracy': 0.9163593256059009, 'eval_runtime': 1.107, 'eval_samples_per_second': 113.821, 'eval_steps_per_second': 7.227, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 130/189 [00:54<00:34,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2246, 'grad_norm': 1.78065824508667, 'learning_rate': 6.243386243386243e-06, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 140/189 [00:57<00:18,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.213, 'grad_norm': 1.284313678741455, 'learning_rate': 5.185185185185185e-06, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 150/189 [01:01<00:14,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2176, 'grad_norm': 1.2121782302856445, 'learning_rate': 4.126984126984127e-06, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 160/189 [01:05<00:10,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2238, 'grad_norm': 1.2065999507904053, 'learning_rate': 3.068783068783069e-06, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 170/189 [01:09<00:07,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1912, 'grad_norm': 1.5118227005004883, 'learning_rate': 2.0105820105820108e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 180/189 [01:12<00:03,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2279, 'grad_norm': 1.275444746017456, 'learning_rate': 9.523809523809525e-07, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:16<00:00,  3.21it/s]c:\\Users\\HikaLipp\\miniconda3\\envs\\TxM\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                 \n",
      "100%|██████████| 189/189 [01:18<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2564546465873718, 'eval_ADR': {'precision': 0.41148325358851673, 'recall': 0.5172932330827068, 'f1': 0.45836109260493, 'number': 665}, 'eval_DIS': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 58}, 'eval_DRU': {'precision': 0.8484107579462102, 'recall': 0.8675, 'f1': 0.857849196538937, 'number': 400}, 'eval_SYM': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 50}, 'eval_overall_precision': 0.5550200803212851, 'eval_overall_recall': 0.5890878090366581, 'eval_overall_f1': 0.5715467328370554, 'eval_overall_accuracy': 0.9190595363540569, 'eval_runtime': 1.1124, 'eval_samples_per_second': 113.267, 'eval_steps_per_second': 7.192, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [01:19<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 79.7466, 'train_samples_per_second': 37.544, 'train_steps_per_second': 2.37, 'train_loss': 0.3579519532975696, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.3579519532975696, metrics={'train_runtime': 79.7466, 'train_samples_per_second': 37.544, 'train_steps_per_second': 2.37, 'total_flos': 782372000176128.0, 'train_loss': 0.3579519532975696, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "# Load metric for evaluation\n",
    "metric = load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    predictions, labels = predictions\n",
    "    predictions = torch.argmax(torch.tensor(predictions), dim=2)\n",
    "    \n",
    "    # Convert predictions and labels to CPU and then to plain Python integers\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    \n",
    "    true_labels = [\n",
    "        [id_to_label[label] for label in label_seq if label != -100] \n",
    "        for label_seq in labels\n",
    "    ]\n",
    "    true_predictions = [\n",
    "        [id_to_label[int(p)] for (p, l) in zip(prediction, label_seq) if l != -100]  # Convert tensor to int\n",
    "        for prediction, label_seq in zip(predictions, labels)\n",
    "    ]\n",
    "    return metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:00<00:00,  8.95it/s]c:\\Users\\HikaLipp\\miniconda3\\envs\\TxM\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.2564546465873718, 'eval_ADR': {'precision': 0.41148325358851673, 'recall': 0.5172932330827068, 'f1': 0.45836109260493, 'number': 665}, 'eval_DIS': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 58}, 'eval_DRU': {'precision': 0.8484107579462102, 'recall': 0.8675, 'f1': 0.857849196538937, 'number': 400}, 'eval_SYM': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 50}, 'eval_overall_precision': 0.5550200803212851, 'eval_overall_recall': 0.5890878090366581, 'eval_overall_f1': 0.5715467328370554, 'eval_overall_accuracy': 0.9190595363540569, 'eval_runtime': 1.131, 'eval_samples_per_second': 111.407, 'eval_steps_per_second': 7.073, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train and test on val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. HPO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TxM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
